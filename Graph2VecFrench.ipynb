{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grapheme Embedding Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import tqdm\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint,shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-139b1b66513b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"data/francais.txt\",encoding='latin-1').read()\n",
    "text = (re.sub(r'[^\\w\\s]','',text.lower())).replace(' ','')\n",
    "\n",
    "tokens=[]\n",
    "vocab = {'$','£'}\n",
    "for term in text.split('\\n'):\n",
    "    #print(set(term))\n",
    "    vocab.update(term)\n",
    "    tokens.append(list(\"$$\"+term+\"£\"))\n",
    "shuffle(tokens)\n",
    "vocab = list(vocab)\n",
    "v=len(vocab)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph2int(graph):\n",
    "    return vocab.index(graph)\n",
    "    \n",
    "def int2graph(index):\n",
    "    return vocab[index]\n",
    "\n",
    "def int2vec(integer):\n",
    "    vec=np.zeros(len(vocab))\n",
    "    vec[integer]=1\n",
    "    return vec\n",
    "\n",
    "def graph2vec(graph):\n",
    "    return (int2vec(graph2int(graph)))\n",
    "\n",
    "def vec2graph(vec):\n",
    "    return (int2graph(np.argmax(vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', '$', 'c', 'o', 'm', 'm', 'e', 'n', 't', 'e', 'r', 'a', 'i', 't', '£']\n"
     ]
    }
   ],
   "source": [
    "windowSize = 2\n",
    "tokens = [tokenSet for tokenSet in tokens if len(tokenSet)>=6]\n",
    "print(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:02<00:00, 20.65it/s]\n"
     ]
    }
   ],
   "source": [
    "x_data = torch.empty(size=(1,2,v))\n",
    "y_data = torch.empty(size=(1,1))\n",
    "\n",
    "freqs= torch.zeros(size=(1,v))\n",
    "\n",
    "i=0\n",
    "N=len(tokens)\n",
    "for word in tqdm.tqdm(tokens[:5000]):\n",
    "    wc = len(word)\n",
    "    for graph_i in range(wc-2): \n",
    "        data_sample = torch.tensor([graph2vec(word[graph_i]), graph2vec(word[graph_i+1])]).unsqueeze(0).float()\n",
    "        x_data = torch.cat([x_data,data_sample])\n",
    "        label_sample = torch.tensor([graph2int(word[graph_i+2])]).unsqueeze(0).float()\n",
    "        y_data = torch.cat([y_data,label_sample])\n",
    "        freqs += graph2vec(word[graph_i+2])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "x_data=x_data[1:,:,:]\n",
    "y_data=y_data[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([54029, 2, 45])\n",
      "torch.Size([54029, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,grapheme_shape,hidden_units,embedding_units):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.word_shape = grapheme_shape\n",
    "        self.hidden_units = hidden_units\n",
    "        self.embedding_units = embedding_units\n",
    "        \n",
    "        self.weights_1 = nn.Parameter(torch.empty(size=(hidden_units, grapheme_shape), requires_grad=True))\n",
    "        nn.init.normal_(self.weights_1)\n",
    "        \n",
    "        self.weights_2 = nn.Parameter(torch.empty(size=(embedding_units, hidden_units), requires_grad=True))\n",
    "        nn.init.normal_(self.weights_2)\n",
    "        \n",
    "        self.bias1 = nn.Parameter(torch.zeros(hidden_units), requires_grad=True)\n",
    "        self.bias2 = nn.Parameter(torch.zeros(embedding_units), requires_grad=True)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        out = F.linear(inputs, self.weights_1, self.bias1)\n",
    "        out = nn.ReLU().forward(out)\n",
    "        out = F.linear(out, self.weights_2,self.bias2)\n",
    "        out = nn.ReLU().forward(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,embedding_units,layer_1_n,grapheme_shape,encoder):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.e = encoder\n",
    "        self.embedding_units=embedding_units\n",
    "        self.layer_1_n = layer_1_n\n",
    "\n",
    "        self.weights_layer1 = nn.Parameter(torch.empty(size=(self.layer_1_n, self.embedding_units*2), requires_grad=True))\n",
    "        nn.init.normal_(self.weights_layer1)\n",
    "        self.bias_layer1 = nn.Parameter(torch.zeros(layer_1_n), requires_grad=True)\n",
    "\n",
    "        self.weights_output = nn.Parameter(torch.empty(size=(grapheme_shape, self.layer_1_n), requires_grad=True))\n",
    "        nn.init.normal_(self.weights_output)\n",
    "        self.bias = nn.Parameter(torch.zeros(grapheme_shape), requires_grad=True)\n",
    "        \n",
    "      \n",
    "    def forward(self,inputs):\n",
    "        embedding1 = self.e.forward(inputs[:,0])\n",
    "        embedding2 = self.e.forward(inputs[:,1])\n",
    "\n",
    "        out = torch.cat((embedding1,embedding2),dim=1)\n",
    "\n",
    "        out = nn.ReLU().forward(F.linear(out, self.weights_layer1, self.bias_layer1))\n",
    "\n",
    "        out = nn.ReLU().forward(F.linear(out, self.weights_output, self.bias))\n",
    "   \n",
    "        return out\n",
    "    \n",
    "    def encode(self,inputs):\n",
    "        return self.e.forward(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.80\n",
    "batch_size = 256\n",
    "\n",
    "trn_n = int(x_data.shape[0] * 0.8)\n",
    "batches = (int(trn_n/batch_size))\n",
    "\n",
    "x_trn = x_data[:trn_n,:,:].clone()\n",
    "y_trn = y_data[:trn_n,:].clone()\n",
    "\n",
    "x_val = x_data[trn_n:,:,:].clone()\n",
    "y_val = y_data[trn_n:,:].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Validation Loss: 8.965091705322266\n",
      "Train Loss:      17.11808415253957\n",
      "\n",
      "\n",
      "Epoch:1\n",
      "Validation Loss: 4.410715103149414\n",
      "Train Loss:      6.062275233722868\n",
      "\n",
      "\n",
      "Epoch:2\n",
      "Validation Loss: 3.332700490951538\n",
      "Train Loss:      3.6986660928953263\n",
      "\n",
      "\n",
      "Epoch:3\n",
      "Validation Loss: 3.00250244140625\n",
      "Train Loss:      3.1101183621656325\n",
      "\n",
      "\n",
      "Epoch:4\n",
      "Validation Loss: 2.8256444931030273\n",
      "Train Loss:      2.8746701734406606\n",
      "\n",
      "\n",
      "Epoch:5\n",
      "Validation Loss: 2.6824233531951904\n",
      "Train Loss:      2.726026767776126\n",
      "\n",
      "\n",
      "Epoch:6\n",
      "Validation Loss: 2.5256476402282715\n",
      "Train Loss:      2.575537241640545\n",
      "\n",
      "\n",
      "Epoch:7\n",
      "Validation Loss: 2.4050846099853516\n",
      "Train Loss:      2.4287619647525607\n",
      "\n",
      "\n",
      "Epoch:8\n",
      "Validation Loss: 2.3271660804748535\n",
      "Train Loss:      2.329120709782555\n",
      "\n",
      "\n",
      "Epoch:9\n",
      "Validation Loss: 2.2733631134033203\n",
      "Train Loss:      2.2629564560595012\n",
      "\n",
      "\n",
      "Epoch:10\n",
      "Validation Loss: 2.234447479248047\n",
      "Train Loss:      2.218474256140845\n",
      "\n",
      "\n",
      "Epoch:11\n",
      "Validation Loss: 2.203754425048828\n",
      "Train Loss:      2.1859606163842336\n",
      "\n",
      "\n",
      "Epoch:12\n",
      "Validation Loss: 2.178590774536133\n",
      "Train Loss:      2.1599157573211762\n",
      "\n",
      "\n",
      "Epoch:13\n",
      "Validation Loss: 2.1577515602111816\n",
      "Train Loss:      2.1383159430254075\n",
      "\n",
      "\n",
      "Epoch:14\n",
      "Validation Loss: 2.139315366744995\n",
      "Train Loss:      2.1200189164706638\n",
      "\n",
      "\n",
      "Epoch:15\n",
      "Validation Loss: 2.1234495639801025\n",
      "Train Loss:      2.1041315013454076\n",
      "\n",
      "\n",
      "Epoch:16\n",
      "Validation Loss: 2.109309434890747\n",
      "Train Loss:      2.090014478280431\n",
      "\n",
      "\n",
      "Epoch:17\n",
      "Validation Loss: 2.0950064659118652\n",
      "Train Loss:      2.0763931764023646\n",
      "\n",
      "\n",
      "Epoch:18\n",
      "Validation Loss: 2.082231044769287\n",
      "Train Loss:      2.0624194535471143\n",
      "\n",
      "\n",
      "Epoch:19\n",
      "Validation Loss: 2.0706350803375244\n",
      "Train Loss:      2.0504425650551203\n",
      "\n",
      "\n",
      "Epoch:20\n",
      "Validation Loss: 2.0593814849853516\n",
      "Train Loss:      2.0391450311456407\n",
      "\n",
      "\n",
      "Epoch:21\n",
      "Validation Loss: 2.0486176013946533\n",
      "Train Loss:      2.0282531558048156\n",
      "\n",
      "\n",
      "Epoch:22\n",
      "Validation Loss: 2.0388081073760986\n",
      "Train Loss:      2.0185057733740126\n",
      "\n",
      "\n",
      "Epoch:23\n",
      "Validation Loss: 2.0300283432006836\n",
      "Train Loss:      2.0097251655090425\n",
      "\n",
      "\n",
      "Epoch:24\n",
      "Validation Loss: 2.02215313911438\n",
      "Train Loss:      2.001745030283928\n",
      "\n",
      "\n",
      "Epoch:25\n",
      "Validation Loss: 2.014540672302246\n",
      "Train Loss:      1.9940491652204877\n",
      "\n",
      "\n",
      "Epoch:26\n",
      "Validation Loss: 2.0078227519989014\n",
      "Train Loss:      1.9866076459487279\n",
      "\n",
      "\n",
      "Epoch:27\n",
      "Validation Loss: 2.000927686691284\n",
      "Train Loss:      1.9796563372725533\n",
      "\n",
      "\n",
      "Epoch:28\n",
      "Validation Loss: 1.9940195083618164\n",
      "Train Loss:      1.9727163329010917\n",
      "\n",
      "\n",
      "Epoch:29\n",
      "Validation Loss: 1.9880123138427734\n",
      "Train Loss:      1.9662297368049622\n",
      "\n",
      "\n",
      "Epoch:30\n",
      "Validation Loss: 1.9819986820220947\n",
      "Train Loss:      1.959973380679176\n",
      "\n",
      "\n",
      "Epoch:31\n",
      "Validation Loss: 1.9762136936187744\n",
      "Train Loss:      1.9542760799328487\n",
      "\n",
      "\n",
      "Epoch:32\n",
      "Validation Loss: 1.970350980758667\n",
      "Train Loss:      1.9484800029368627\n",
      "\n",
      "\n",
      "Epoch:33\n",
      "Validation Loss: 1.9644441604614258\n",
      "Train Loss:      1.9427245897906167\n",
      "\n",
      "\n",
      "Epoch:34\n",
      "Validation Loss: 1.9590164422988892\n",
      "Train Loss:      1.9370547859441667\n",
      "\n",
      "\n",
      "Epoch:35\n",
      "Validation Loss: 1.9539709091186523\n",
      "Train Loss:      1.931577776159559\n",
      "\n",
      "\n",
      "Epoch:36\n",
      "Validation Loss: 1.9468673467636108\n",
      "Train Loss:      1.9257581865503675\n",
      "\n",
      "\n",
      "Epoch:37\n",
      "Validation Loss: 1.9407085180282593\n",
      "Train Loss:      1.9189676699184237\n",
      "\n",
      "\n",
      "Epoch:38\n",
      "Validation Loss: 1.9339110851287842\n",
      "Train Loss:      1.9128058098611378\n",
      "\n",
      "\n",
      "Epoch:39\n",
      "Validation Loss: 1.928245186805725\n",
      "Train Loss:      1.9067386445545016\n",
      "\n",
      "\n",
      "Epoch:40\n",
      "Validation Loss: 1.9235121011734009\n",
      "Train Loss:      1.9019046752225786\n",
      "\n",
      "\n",
      "Epoch:41\n",
      "Validation Loss: 1.919129490852356\n",
      "Train Loss:      1.8978951282444454\n",
      "\n",
      "\n",
      "Epoch:42\n",
      "Validation Loss: 1.9151480197906494\n",
      "Train Loss:      1.894201228306407\n",
      "\n",
      "\n",
      "Epoch:43\n",
      "Validation Loss: 1.9118281602859497\n",
      "Train Loss:      1.8909274254526411\n",
      "\n",
      "\n",
      "Epoch:44\n",
      "Validation Loss: 1.9089802503585815\n",
      "Train Loss:      1.8879963705937068\n",
      "\n",
      "\n",
      "Epoch:45\n",
      "Validation Loss: 1.906186819076538\n",
      "Train Loss:      1.8853260619299752\n",
      "\n",
      "\n",
      "Epoch:46\n",
      "Validation Loss: 1.903745412826538\n",
      "Train Loss:      1.8827310850222905\n",
      "\n",
      "\n",
      "Epoch:47\n",
      "Validation Loss: 1.9014414548873901\n",
      "Train Loss:      1.8802179488397779\n",
      "\n",
      "\n",
      "Epoch:48\n",
      "Validation Loss: 1.8992301225662231\n",
      "Train Loss:      1.8777182059628623\n",
      "\n",
      "\n",
      "Epoch:49\n",
      "Validation Loss: 1.8970340490341187\n",
      "Train Loss:      1.8753437704983211\n",
      "\n",
      "\n",
      "Epoch:50\n",
      "Validation Loss: 1.8949990272521973\n",
      "Train Loss:      1.8732315479289918\n",
      "\n",
      "\n",
      "Epoch:51\n",
      "Validation Loss: 1.8932034969329834\n",
      "Train Loss:      1.8711847769362586\n",
      "\n",
      "\n",
      "Epoch:52\n",
      "Validation Loss: 1.8916248083114624\n",
      "Train Loss:      1.8693308560621171\n",
      "\n",
      "\n",
      "Epoch:53\n",
      "Validation Loss: 1.8898231983184814\n",
      "Train Loss:      1.8675654466663087\n",
      "\n",
      "\n",
      "Epoch:54\n",
      "Validation Loss: 1.8880927562713623\n",
      "Train Loss:      1.8657733656111217\n",
      "\n",
      "\n",
      "Epoch:55\n",
      "Validation Loss: 1.8854366540908813\n",
      "Train Loss:      1.86371649092152\n",
      "\n",
      "\n",
      "Epoch:56\n",
      "Validation Loss: 1.8816826343536377\n",
      "Train Loss:      1.8604281885283334\n",
      "\n",
      "\n",
      "Epoch:57\n",
      "Validation Loss: 1.8780308961868286\n",
      "Train Loss:      1.8574161593403136\n",
      "\n",
      "\n",
      "Epoch:58\n",
      "Validation Loss: 1.8726136684417725\n",
      "Train Loss:      1.8531146610067004\n",
      "\n",
      "\n",
      "Epoch:59\n",
      "Validation Loss: 1.8695838451385498\n",
      "Train Loss:      1.8495412397952307\n",
      "\n",
      "\n",
      "Epoch:60\n",
      "Validation Loss: 1.8675031661987305\n",
      "Train Loss:      1.8472348018771125\n",
      "\n",
      "\n",
      "Epoch:61\n",
      "Validation Loss: 1.8653242588043213\n",
      "Train Loss:      1.8453539929219656\n",
      "\n",
      "\n",
      "Epoch:62\n",
      "Validation Loss: 1.8637778759002686\n",
      "Train Loss:      1.843603720977193\n",
      "\n",
      "\n",
      "Epoch:63\n",
      "Validation Loss: 1.8620656728744507\n",
      "Train Loss:      1.8421736671811058\n",
      "\n",
      "\n",
      "Epoch:64\n",
      "Validation Loss: 1.8605144023895264\n",
      "Train Loss:      1.840595693105743\n",
      "\n",
      "\n",
      "Epoch:65\n",
      "Validation Loss: 1.8591538667678833\n",
      "Train Loss:      1.8392714297487622\n",
      "\n",
      "\n",
      "Epoch:66\n",
      "Validation Loss: 1.8578639030456543\n",
      "Train Loss:      1.8379290125199728\n",
      "\n",
      "\n",
      "Epoch:67\n",
      "Validation Loss: 1.856518268585205\n",
      "Train Loss:      1.8367102025520234\n",
      "\n",
      "\n",
      "Epoch:68\n",
      "Validation Loss: 1.8551876544952393\n",
      "Train Loss:      1.8353334636915297\n",
      "\n",
      "\n",
      "Epoch:69\n",
      "Validation Loss: 1.8539921045303345\n",
      "Train Loss:      1.8341211825609207\n",
      "\n",
      "\n",
      "Epoch:70\n",
      "Validation Loss: 1.852660059928894\n",
      "Train Loss:      1.8327411179031645\n",
      "\n",
      "\n",
      "Epoch:71\n",
      "Validation Loss: 1.8512893915176392\n",
      "Train Loss:      1.8314325788191386\n",
      "\n",
      "\n",
      "Epoch:72\n",
      "Validation Loss: 1.8499689102172852\n",
      "Train Loss:      1.8300626831395286\n",
      "\n",
      "\n",
      "Epoch:73\n",
      "Validation Loss: 1.848492980003357\n",
      "Train Loss:      1.828640682356698\n",
      "\n",
      "\n",
      "Epoch:74\n",
      "Validation Loss: 1.8473196029663086\n",
      "Train Loss:      1.8273033570675623\n",
      "\n",
      "\n",
      "Epoch:75\n",
      "Validation Loss: 1.8461538553237915\n",
      "Train Loss:      1.8261135561125619\n",
      "\n",
      "\n",
      "Epoch:76\n",
      "Validation Loss: 1.8451730012893677\n",
      "Train Loss:      1.8249524377641224\n",
      "\n",
      "\n",
      "Epoch:77\n",
      "Validation Loss: 1.844456434249878\n",
      "Train Loss:      1.823905077718553\n",
      "\n",
      "\n",
      "Epoch:78\n",
      "Validation Loss: 1.8433350324630737\n",
      "Train Loss:      1.822927754549753\n",
      "\n",
      "\n",
      "Epoch:79\n",
      "Validation Loss: 1.8425650596618652\n",
      "Train Loss:      1.8219251547540938\n",
      "\n",
      "\n",
      "Epoch:80\n",
      "Validation Loss: 1.8416719436645508\n",
      "Train Loss:      1.820959026614825\n",
      "\n",
      "\n",
      "Epoch:81\n",
      "Validation Loss: 1.8409019708633423\n",
      "Train Loss:      1.8199760580346698\n",
      "\n",
      "\n",
      "Epoch:82\n",
      "Validation Loss: 1.8401613235473633\n",
      "Train Loss:      1.8191602535191036\n",
      "\n",
      "\n",
      "Epoch:83\n",
      "Validation Loss: 1.8393962383270264\n",
      "Train Loss:      1.8183174637101946\n",
      "\n",
      "\n",
      "Epoch:84\n",
      "Validation Loss: 1.8388108015060425\n",
      "Train Loss:      1.817572410617556\n",
      "\n",
      "\n",
      "Epoch:85\n",
      "Validation Loss: 1.8382246494293213\n",
      "Train Loss:      1.8167961871340161\n",
      "\n",
      "\n",
      "Epoch:86\n",
      "Validation Loss: 1.8377153873443604\n",
      "Train Loss:      1.8161052273852485\n",
      "\n",
      "\n",
      "Epoch:87\n",
      "Validation Loss: 1.8370027542114258\n",
      "Train Loss:      1.8153991216704959\n",
      "\n",
      "\n",
      "Epoch:88\n",
      "Validation Loss: 1.8362089395523071\n",
      "Train Loss:      1.8147170628820146\n",
      "\n",
      "\n",
      "Epoch:89\n",
      "Validation Loss: 1.8357435464859009\n",
      "Train Loss:      1.8140946860824312\n",
      "\n",
      "\n",
      "Epoch:90\n",
      "Validation Loss: 1.8347077369689941\n",
      "Train Loss:      1.813434450399308\n",
      "\n",
      "\n",
      "Epoch:91\n",
      "Validation Loss: 1.8339946269989014\n",
      "Train Loss:      1.8127339290721076\n",
      "\n",
      "\n",
      "Epoch:92\n",
      "Validation Loss: 1.8334591388702393\n",
      "Train Loss:      1.8120357060716266\n",
      "\n",
      "\n",
      "Epoch:93\n",
      "Validation Loss: 1.8326176404953003\n",
      "Train Loss:      1.8114134193885894\n",
      "\n",
      "\n",
      "Epoch:94\n",
      "Validation Loss: 1.8319634199142456\n",
      "Train Loss:      1.8106872049115954\n",
      "\n",
      "\n",
      "Epoch:95\n",
      "Validation Loss: 1.8312593698501587\n",
      "Train Loss:      1.809967224796613\n",
      "\n",
      "\n",
      "Epoch:96\n",
      "Validation Loss: 1.8304831981658936\n",
      "Train Loss:      1.8092669610466277\n",
      "\n",
      "\n",
      "Epoch:97\n",
      "Validation Loss: 1.829949975013733\n",
      "Train Loss:      1.8084547065553211\n",
      "\n",
      "\n",
      "Epoch:98\n",
      "Validation Loss: 1.8293596506118774\n",
      "Train Loss:      1.8076943308115005\n",
      "\n",
      "\n",
      "Epoch:99\n",
      "Validation Loss: 1.8289690017700195\n",
      "Train Loss:      1.8070693633386068\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_dict = {'losses_trn': [],'losses_val':[]} \n",
    "encoder =  Encoder(grapheme_shape=v,hidden_units=10,embedding_units=10)\n",
    "decoder = Decoder(embedding_units=10,layer_1_n=15,grapheme_shape=v,encoder=encoder)\n",
    "optimizer = optim.Adam(decoder.parameters(), amsgrad=False, weight_decay=0.0)\n",
    "\n",
    "trn_loss = nn.NLLLoss(weight=freqs.float())\n",
    "val_loss = nn.NLLLoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    print(\"Epoch:\" + str(epoch))\n",
    "    epoch_trn_loss_sum = 0\n",
    "    for batch in (range(batches)):\n",
    "        x_batch = x_trn[batch_size*batch:batch_size*(batch+1)]\n",
    "        y_batch = y_trn[batch_size*batch:batch_size*(batch+1)]\n",
    "        \n",
    "        out = decoder.forward(x_batch)\n",
    "        log_softmax = F.log_softmax(out, dim=1).unsqueeze(2)\n",
    "        \n",
    "       \n",
    "        \n",
    "        NLL_Loss = trn_loss(log_softmax,y_batch.long()) \n",
    "        optimizer.zero_grad()\n",
    "        NLL_Loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_trn_loss_sum += NLL_Loss.item()\n",
    "        \n",
    "    out_val = decoder.forward(x_val)\n",
    "    log_val_softmax = F.log_softmax(out_val, dim=1).unsqueeze(2)\n",
    "    NLL_val_loss = trn_loss(log_val_softmax, y_val.long())\n",
    "    \n",
    "    epoch_trn_loss = epoch_trn_loss_sum/batches\n",
    "    print(\"Validation Loss: \"+str(NLL_val_loss.item()))\n",
    "    print(\"Train Loss:      \"+str(epoch_trn_loss))\n",
    "    print(\"\\n\")\n",
    "   # print(\"Val: \"+str(val_loss.item()))\n",
    "    metric_dict['losses_trn'].append(NLL_Loss.item())\n",
    "    metric_dict['losses_val'].append(epoch_trn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbfa15a0d10>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(metric_dict['losses_trn'][:100])\n",
    "plt.plot(metric_dict['losses_val'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = np.zeros(shape=(len(vocab),10))\n",
    "\n",
    "i=0\n",
    "for grapheme in vocab:\n",
    "    test = torch.from_numpy(graph2vec(grapheme)).float()\n",
    "    embedding = decoder.encode(test).detach().numpy()\n",
    "    embeddings[i,:]=embedding\n",
    "    i+=1\n",
    "\n",
    "\n",
    "\n",
    "embedding_means = embeddings.mean(axis=0)\n",
    "embedding_std = embeddings.std(axis=0)\n",
    "norm_embeddings = (embeddings-embedding_means)/embedding_std\n",
    "\n",
    "    \n",
    "covariance_matrix = np.cov(norm_embeddings.T)\n",
    "v,w = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "idx = v.argsort()[::-1] # Sort descending and get sorted indices\n",
    "v = v[idx] # Use indices on eigv vector\n",
    "w = w[:,idx] # \n",
    "\n",
    "variance_explained = []\n",
    "for i in v:\n",
    "     variance_explained.append((i/sum(v))*100)\n",
    "        \n",
    "red_Vecs = w[0:2,:]\n",
    "\n",
    "low_d_embed = (embeddings @ red_Vecs.T)\n",
    "\n",
    "#plt.scatter(x=low_d_embed[:,0],y=low_d_embed[:,1])\n",
    "\n",
    "x=low_d_embed[:,0]\n",
    "y=low_d_embed[:,1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y,color='white')\n",
    "\n",
    "for i, txt in enumerate(vocab):\n",
    "    ax.annotate(txt, (x[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', 'g']\n",
      "Prediction: $g r\n",
      "True:       $g o\n"
     ]
    }
   ],
   "source": [
    "n=randint(0,x_trn.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "input = x_trn[n,:,:].unsqueeze(0)\n",
    "output = y_trn[n,:]\n",
    "\n",
    "out=decoder.forward(input)\n",
    "log_softmax = -F.log_softmax(out, dim=1)\n",
    "\n",
    "p=(log_softmax.argmin(dim=1).detach().numpy()[0])\n",
    "o=(output.int().numpy())\n",
    "\n",
    "numpy_input = input.int().detach().numpy()[0]\n",
    "inp_ind = (numpy_input.argmax(axis=1))\n",
    "inp_let = [vocab[i] for i in inp_ind]\n",
    "\n",
    "\n",
    "print(inp_let)\n",
    "print(\"Prediction: \" + ''.join(inp_let)+\" \"+str(vocab[p]))\n",
    "print(\"True:       \" + ''.join(inp_let)+\" \"+str(vocab[o[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', '$', 'é', 'p', 'a', 'n', 'd', 'r', 'i', 'o', 'n', 's']\n",
      "['o', 'n']\n",
      "16\n",
      "['o', 'n']\n",
      "Prediction: $$épandrion s\n",
      "True:       $$épandrion s\n"
     ]
    }
   ],
   "source": [
    "n=randint(0,len(tokens))\n",
    "token=(tokens[n])[:-1]\n",
    "print(token)\n",
    "\n",
    "input = token[-3:-1]\n",
    "\n",
    "#input = x_trn[n,:,:].unsqueeze(0)\n",
    "output = token[-1:][0]\n",
    "\n",
    "input = torch.tensor([graph2vec(input[0]),graph2vec(input[1])]).unsqueeze(0).float()\n",
    "\n",
    "out=decoder.forward(input)\n",
    "log_softmax = -F.log_softmax(out, dim=1)\n",
    "\n",
    "p=(log_softmax.argmin(dim=1).detach().numpy()[0])\n",
    "o=(output)\n",
    "\n",
    "numpy_input = input.int().detach().numpy()[0]\n",
    "inp_ind = (numpy_input.argmax(axis=1))\n",
    "inp_let = [vocab[i] for i in inp_ind]\n",
    "print(inp_let)\n",
    "print(p)\n",
    "\n",
    "\n",
    "print(inp_let)\n",
    "print(\"Prediction: \" + ''.join(token[:-1])+\" \"+str(vocab[p]))\n",
    "print(\"True:       \" + ''.join(token[:-1])+\" \"+str(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamois nerais orsatermions rraies ins emons eromeriant es rieonne erionr\n"
     ]
    }
   ],
   "source": [
    "n=randint(0,len(tokens))\n",
    "token=(tokens[n])[:-1]\n",
    "\n",
    "sentence = []\n",
    "\n",
    "for i in range(10):\n",
    "    string = \"$$\"\n",
    "\n",
    "    while True:\n",
    "\n",
    "        input=string[-2:]\n",
    "        input = torch.tensor([graph2vec(input[0]),graph2vec(input[1])]).unsqueeze(0).float()\n",
    "\n",
    "        out=decoder.forward(input)\n",
    "        probs = F.softmax(out, dim=1).detach().numpy()[0]\n",
    "\n",
    "        sample = np.random.multinomial(1, probs)\n",
    "        ids = np.argmax(sample)\n",
    "\n",
    "        #p=(log_softmax.argmin(dim=1).detach().numpy()[0])\n",
    "\n",
    "        grapheme = str(vocab[ids])\n",
    "\n",
    "        string+=grapheme\n",
    "        if grapheme ==\"£\":\n",
    "            break\n",
    "        \n",
    "    #print(string)\n",
    "    string = string.split('$')[2:][0]\n",
    "    string = string.split('£')[:-1][0]\n",
    "    sentence.append(string)\n",
    "\n",
    "print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbour of a : c\n",
      "Nearest neighbour of b : p\n",
      "Nearest neighbour of c : f\n",
      "Nearest neighbour of d : z\n",
      "Nearest neighbour of e : s\n",
      "Nearest neighbour of f : x\n",
      "Nearest neighbour of g : q\n",
      "Nearest neighbour of h : r\n",
      "Nearest neighbour of i : k\n",
      "Nearest neighbour of j : w\n",
      "Nearest neighbour of k : i\n",
      "Nearest neighbour of l : d\n",
      "Nearest neighbour of m : x\n",
      "Nearest neighbour of n : r\n",
      "Nearest neighbour of o : a\n",
      "Nearest neighbour of p : b\n",
      "Nearest neighbour of q : s\n",
      "Nearest neighbour of r : n\n",
      "Nearest neighbour of s : t\n",
      "Nearest neighbour of t : s\n",
      "Nearest neighbour of u : b\n",
      "Nearest neighbour of v : $\n",
      "Nearest neighbour of w : $\n",
      "Nearest neighbour of x : f\n",
      "Nearest neighbour of y : t\n",
      "Nearest neighbour of z : £\n",
      "Nearest neighbour of $ : v\n",
      "Nearest neighbour of £ : z\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.zeros(shape=(len(vocab),10))\n",
    "\n",
    "i=0\n",
    "for grapheme in vocab:\n",
    "    test = torch.from_numpy(graph2vec(grapheme)).float()\n",
    "    embedding = decoder.encode(test).detach().numpy()\n",
    "    embeddings[i,:]=embedding\n",
    "    i+=1\n",
    "    \n",
    "l=0\n",
    "for e in (embeddings):\n",
    "    dists=(np.square(embeddings-e).sum(axis=1))\n",
    "    nearest_idx=(np.argsort(dists)[1])\n",
    "    print(\"Nearest neighbour of \"+vocab[l]+\" : \"+vocab[nearest_idx])\n",
    "    l+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change embedding sizes/ratios\n",
    "change learning rates\n",
    "change scaling\n",
    "\n",
    "work on byte pair encoding/longer grapheme units\n",
    "create duplicate embedding data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
