{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grapheme Embedding Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import tqdm\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint,shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b', 'd', 'e', 'g', 'n', 'r', 'u', 'ä'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set({'d', 'e', 'a', 'g', 'ä', 'n', 'r', 'u', 'b'}) or set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"data/deutsch.txt\",encoding='latin-1').read()\n",
    "text = (re.sub(r'[^\\w\\s]','',text.lower())).replace(' ','')\n",
    "\n",
    "tokens=[]\n",
    "vocab = {'$','£'}\n",
    "for term in text.split('\\n'):\n",
    "    #print(set(term))\n",
    "    vocab.update(term)\n",
    "    tokens.append(list(\"$$\"+term+\"£\"))\n",
    "shuffle(tokens)\n",
    "vocab = list(vocab)\n",
    "v=len(vocab)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph2int(graph):\n",
    "    return vocab.index(graph)\n",
    "    \n",
    "def int2graph(index):\n",
    "    return vocab[index]\n",
    "\n",
    "def int2vec(integer):\n",
    "    vec=np.zeros(len(vocab))\n",
    "    vec[integer]=1\n",
    "    return vec\n",
    "\n",
    "def graph2vec(graph):\n",
    "    return (int2vec(graph2int(graph)))\n",
    "\n",
    "def vec2graph(vec):\n",
    "    return (int2graph(np.argmax(vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', '$', 'z', 'u', 'r', 'ü', 'c', 'k', 'k', 'e', 'h', 'r', 't', 'e', '£']\n"
     ]
    }
   ],
   "source": [
    "windowSize = 2\n",
    "tokens = [tokenSet for tokenSet in tokens if len(tokenSet)>=6]\n",
    "print(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 7537/15000 [09:03<08:57, 13.87it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b50e2325faac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgraph_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwc\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdata_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlabel_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph2int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_data = torch.empty(size=(1,2,v))\n",
    "y_data = torch.empty(size=(1,1))\n",
    "\n",
    "freqs= torch.zeros(size=(1,v))\n",
    "\n",
    "i=0\n",
    "N=len(tokens)\n",
    "for word in tqdm.tqdm(tokens[:15000]):\n",
    "    wc = len(word)\n",
    "    for graph_i in range(wc-2): \n",
    "        data_sample = torch.tensor([graph2vec(word[graph_i]), graph2vec(word[graph_i+1])]).unsqueeze(0).float()\n",
    "        x_data = torch.cat([x_data,data_sample])\n",
    "        label_sample = torch.tensor([graph2int(word[graph_i+2])]).unsqueeze(0).float()\n",
    "        y_data = torch.cat([y_data,label_sample])\n",
    "        freqs += graph2vec(word[graph_i+2])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "x_data=x_data[1:,:,:]\n",
    "y_data=y_data[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([92549, 2, 35])\n",
      "torch.Size([92549, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,grapheme_shape,hidden_units,embedding_units):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.word_shape = grapheme_shape\n",
    "        self.hidden_units = hidden_units\n",
    "        self.embedding_units = embedding_units\n",
    "        \n",
    "        self.weights_1 = nn.Parameter(torch.empty(size=(hidden_units, grapheme_shape), requires_grad=True))\n",
    "        nn.init.normal_(self.weights_1)\n",
    "        \n",
    "        self.weights_2 = nn.Parameter(torch.empty(size=(embedding_units, hidden_units), requires_grad=True))\n",
    "        nn.init.normal_(self.weights_2)\n",
    "        \n",
    "        self.bias1 = nn.Parameter(torch.zeros(hidden_units), requires_grad=True)\n",
    "        self.bias2 = nn.Parameter(torch.zeros(embedding_units), requires_grad=True)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        out = F.linear(inputs, self.weights_1, self.bias1)\n",
    "        out = nn.ReLU().forward(out)\n",
    "        out = F.linear(out, self.weights_2,self.bias2)\n",
    "        out = nn.ReLU().forward(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,embedding_units,layer_1_n,grapheme_shape,encoder):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.e = encoder\n",
    "        self.embedding_units=embedding_units\n",
    "        self.layer_1_n = layer_1_n\n",
    "\n",
    "        self.weights_layer1 = nn.Parameter(torch.empty(size=(self.layer_1_n, self.embedding_units*2), requires_grad=True))\n",
    "        nn.init.normal_(self.weights_layer1)\n",
    "        self.bias_layer1 = nn.Parameter(torch.zeros(layer_1_n), requires_grad=True)\n",
    "\n",
    "        self.weights_output = nn.Parameter(torch.empty(size=(grapheme_shape, self.layer_1_n), requires_grad=True))\n",
    "        nn.init.normal_(self.weights_output)\n",
    "        self.bias = nn.Parameter(torch.zeros(grapheme_shape), requires_grad=True)\n",
    "        \n",
    "      \n",
    "    def forward(self,inputs):\n",
    "        embedding1 = self.e.forward(inputs[:,0])\n",
    "        embedding2 = self.e.forward(inputs[:,1])\n",
    "\n",
    "        out = torch.cat((embedding1,embedding2),dim=1)\n",
    "\n",
    "        out = nn.ReLU().forward(F.linear(out, self.weights_layer1, self.bias_layer1))\n",
    "\n",
    "        out = nn.ReLU().forward(F.linear(out, self.weights_output, self.bias))\n",
    "   \n",
    "        return out\n",
    "    \n",
    "    def encode(self,inputs):\n",
    "        return self.e.forward(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.80\n",
    "batch_size = 256\n",
    "\n",
    "trn_n = int(x_data.shape[0] * 0.8)\n",
    "batches = (int(trn_n/batch_size))\n",
    "\n",
    "x_trn = x_data[:trn_n,:,:].clone()\n",
    "y_trn = y_data[:trn_n,:].clone()\n",
    "\n",
    "x_val = x_data[trn_n:,:,:].clone()\n",
    "y_val = y_data[trn_n:,:].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Validation Loss: 3.8236563205718994\n",
      "Train Loss:      7.6148712486544285\n",
      "\n",
      "\n",
      "Epoch:1\n",
      "Validation Loss: 2.7307941913604736\n",
      "Train Loss:      3.130890585559462\n",
      "\n",
      "\n",
      "Epoch:2\n",
      "Validation Loss: 2.450235605239868\n",
      "Train Loss:      2.568076405145718\n",
      "\n",
      "\n",
      "Epoch:3\n",
      "Validation Loss: 2.258380651473999\n",
      "Train Loss:      2.3542895539821638\n",
      "\n",
      "\n",
      "Epoch:4\n",
      "Validation Loss: 2.1648671627044678\n",
      "Train Loss:      2.2152928476927602\n",
      "\n",
      "\n",
      "Epoch:5\n",
      "Validation Loss: 2.088226795196533\n",
      "Train Loss:      2.133826387794785\n",
      "\n",
      "\n",
      "Epoch:6\n",
      "Validation Loss: 2.035135269165039\n",
      "Train Loss:      2.0717319472850813\n",
      "\n",
      "\n",
      "Epoch:7\n",
      "Validation Loss: 1.9939887523651123\n",
      "Train Loss:      2.0215974976034725\n",
      "\n",
      "\n",
      "Epoch:8\n",
      "Validation Loss: 1.965664267539978\n",
      "Train Loss:      1.9871497682221622\n",
      "\n",
      "\n",
      "Epoch:9\n",
      "Validation Loss: 1.9430179595947266\n",
      "Train Loss:      1.9616279536052559\n",
      "\n",
      "\n",
      "Epoch:10\n",
      "Validation Loss: 1.9226231575012207\n",
      "Train Loss:      1.9404531754424414\n",
      "\n",
      "\n",
      "Epoch:11\n",
      "Validation Loss: 1.8958945274353027\n",
      "Train Loss:      1.9191485944503732\n",
      "\n",
      "\n",
      "Epoch:12\n",
      "Validation Loss: 1.8800686597824097\n",
      "Train Loss:      1.8954732298438524\n",
      "\n",
      "\n",
      "Epoch:13\n",
      "Validation Loss: 1.868850827217102\n",
      "Train Loss:      1.8815966617689825\n",
      "\n",
      "\n",
      "Epoch:14\n",
      "Validation Loss: 1.8587477207183838\n",
      "Train Loss:      1.8701348164502312\n",
      "\n",
      "\n",
      "Epoch:15\n",
      "Validation Loss: 1.841365098953247\n",
      "Train Loss:      1.8574860339346229\n",
      "\n",
      "\n",
      "Epoch:16\n",
      "Validation Loss: 1.7926450967788696\n",
      "Train Loss:      1.8153046617045947\n",
      "\n",
      "\n",
      "Epoch:17\n",
      "Validation Loss: 1.7818242311477661\n",
      "Train Loss:      1.7931308469970333\n",
      "\n",
      "\n",
      "Epoch:18\n",
      "Validation Loss: 1.7727394104003906\n",
      "Train Loss:      1.7837268794696637\n",
      "\n",
      "\n",
      "Epoch:19\n",
      "Validation Loss: 1.765655279159546\n",
      "Train Loss:      1.7760365265050975\n",
      "\n",
      "\n",
      "Epoch:20\n",
      "Validation Loss: 1.7590107917785645\n",
      "Train Loss:      1.7697307246779075\n",
      "\n",
      "\n",
      "Epoch:21\n",
      "Validation Loss: 1.7538185119628906\n",
      "Train Loss:      1.764234417037568\n",
      "\n",
      "\n",
      "Epoch:22\n",
      "Validation Loss: 1.7490148544311523\n",
      "Train Loss:      1.7596822119089146\n",
      "\n",
      "\n",
      "Epoch:23\n",
      "Validation Loss: 1.7449419498443604\n",
      "Train Loss:      1.7555621115806606\n",
      "\n",
      "\n",
      "Epoch:24\n",
      "Validation Loss: 1.7402349710464478\n",
      "Train Loss:      1.7513795105231262\n",
      "\n",
      "\n",
      "Epoch:25\n",
      "Validation Loss: 1.7355849742889404\n",
      "Train Loss:      1.7455844986397502\n",
      "\n",
      "\n",
      "Epoch:26\n",
      "Validation Loss: 1.7319258451461792\n",
      "Train Loss:      1.7416337571754588\n",
      "\n",
      "\n",
      "Epoch:27\n",
      "Validation Loss: 1.728967308998108\n",
      "Train Loss:      1.7384879056970142\n",
      "\n",
      "\n",
      "Epoch:28\n",
      "Validation Loss: 1.725717306137085\n",
      "Train Loss:      1.7356673672949978\n",
      "\n",
      "\n",
      "Epoch:29\n",
      "Validation Loss: 1.7227954864501953\n",
      "Train Loss:      1.7327232257717622\n",
      "\n",
      "\n",
      "Epoch:30\n",
      "Validation Loss: 1.7202811241149902\n",
      "Train Loss:      1.73015194161953\n",
      "\n",
      "\n",
      "Epoch:31\n",
      "Validation Loss: 1.717655062675476\n",
      "Train Loss:      1.7276424602653742\n",
      "\n",
      "\n",
      "Epoch:32\n",
      "Validation Loss: 1.7149728536605835\n",
      "Train Loss:      1.7251080365329465\n",
      "\n",
      "\n",
      "Epoch:33\n",
      "Validation Loss: 1.712527871131897\n",
      "Train Loss:      1.7225430494361271\n",
      "\n",
      "\n",
      "Epoch:34\n",
      "Validation Loss: 1.7104542255401611\n",
      "Train Loss:      1.7204472663905794\n",
      "\n",
      "\n",
      "Epoch:35\n",
      "Validation Loss: 1.7078135013580322\n",
      "Train Loss:      1.7182673459234534\n",
      "\n",
      "\n",
      "Epoch:36\n",
      "Validation Loss: 1.70500910282135\n",
      "Train Loss:      1.7157329943765818\n",
      "\n",
      "\n",
      "Epoch:37\n",
      "Validation Loss: 1.7032390832901\n",
      "Train Loss:      1.7136365035000969\n",
      "\n",
      "\n",
      "Epoch:38\n",
      "Validation Loss: 1.7013236284255981\n",
      "Train Loss:      1.7119851520729725\n",
      "\n",
      "\n",
      "Epoch:39\n",
      "Validation Loss: 1.6998190879821777\n",
      "Train Loss:      1.710162287352407\n",
      "\n",
      "\n",
      "Epoch:40\n",
      "Validation Loss: 1.6979429721832275\n",
      "Train Loss:      1.70855134787444\n",
      "\n",
      "\n",
      "Epoch:41\n",
      "Validation Loss: 1.6955195665359497\n",
      "Train Loss:      1.7065321751531846\n",
      "\n",
      "\n",
      "Epoch:42\n",
      "Validation Loss: 1.693995714187622\n",
      "Train Loss:      1.7045786496264712\n",
      "\n",
      "\n",
      "Epoch:43\n",
      "Validation Loss: 1.6921955347061157\n",
      "Train Loss:      1.702817330723403\n",
      "\n",
      "\n",
      "Epoch:44\n",
      "Validation Loss: 1.6901012659072876\n",
      "Train Loss:      1.701060835465428\n",
      "\n",
      "\n",
      "Epoch:45\n",
      "Validation Loss: 1.684501051902771\n",
      "Train Loss:      1.696389193353356\n",
      "\n",
      "\n",
      "Epoch:46\n",
      "Validation Loss: 1.6819075345993042\n",
      "Train Loss:      1.6919510558402249\n",
      "\n",
      "\n",
      "Epoch:47\n",
      "Validation Loss: 1.6796919107437134\n",
      "Train Loss:      1.6895116534612582\n",
      "\n",
      "\n",
      "Epoch:48\n",
      "Validation Loss: 1.6776238679885864\n",
      "Train Loss:      1.6876941325342778\n",
      "\n",
      "\n",
      "Epoch:49\n",
      "Validation Loss: 1.6743890047073364\n",
      "Train Loss:      1.6851576463573945\n",
      "\n",
      "\n",
      "Epoch:50\n",
      "Validation Loss: 1.6719024181365967\n",
      "Train Loss:      1.6823414522883802\n",
      "\n",
      "\n",
      "Epoch:51\n",
      "Validation Loss: 1.670096755027771\n",
      "Train Loss:      1.6800527807750505\n",
      "\n",
      "\n",
      "Epoch:52\n",
      "Validation Loss: 1.668585181236267\n",
      "Train Loss:      1.6782506007224218\n",
      "\n",
      "\n",
      "Epoch:53\n",
      "Validation Loss: 1.6667449474334717\n",
      "Train Loss:      1.6763826134295612\n",
      "\n",
      "\n",
      "Epoch:54\n",
      "Validation Loss: 1.665238857269287\n",
      "Train Loss:      1.674389582191784\n",
      "\n",
      "\n",
      "Epoch:55\n",
      "Validation Loss: 1.663887858390808\n",
      "Train Loss:      1.6726467811525074\n",
      "\n",
      "\n",
      "Epoch:56\n",
      "Validation Loss: 1.6621462106704712\n",
      "Train Loss:      1.670717071909393\n",
      "\n",
      "\n",
      "Epoch:57\n",
      "Validation Loss: 1.660671353340149\n",
      "Train Loss:      1.668724851212287\n",
      "\n",
      "\n",
      "Epoch:58\n",
      "Validation Loss: 1.6592841148376465\n",
      "Train Loss:      1.6671165937370906\n",
      "\n",
      "\n",
      "Epoch:59\n",
      "Validation Loss: 1.6581251621246338\n",
      "Train Loss:      1.6656264297689947\n",
      "\n",
      "\n",
      "Epoch:60\n",
      "Validation Loss: 1.6570183038711548\n",
      "Train Loss:      1.6643662225828864\n",
      "\n",
      "\n",
      "Epoch:61\n",
      "Validation Loss: 1.6560637950897217\n",
      "Train Loss:      1.663183669317965\n",
      "\n",
      "\n",
      "Epoch:62\n",
      "Validation Loss: 1.6549243927001953\n",
      "Train Loss:      1.6620417998323804\n",
      "\n",
      "\n",
      "Epoch:63\n",
      "Validation Loss: 1.6541554927825928\n",
      "Train Loss:      1.6609696236448717\n",
      "\n",
      "\n",
      "Epoch:64\n",
      "Validation Loss: 1.6531895399093628\n",
      "Train Loss:      1.6599356501160196\n",
      "\n",
      "\n",
      "Epoch:65\n",
      "Validation Loss: 1.6532570123672485\n",
      "Train Loss:      1.6589684189397158\n",
      "\n",
      "\n",
      "Epoch:66\n",
      "Validation Loss: 1.6511603593826294\n",
      "Train Loss:      1.6580978033864375\n",
      "\n",
      "\n",
      "Epoch:67\n",
      "Validation Loss: 1.6500413417816162\n",
      "Train Loss:      1.656837104513571\n",
      "\n",
      "\n",
      "Epoch:68\n",
      "Validation Loss: 1.6493679285049438\n",
      "Train Loss:      1.6558257914744448\n",
      "\n",
      "\n",
      "Epoch:69\n",
      "Validation Loss: 1.6486053466796875\n",
      "Train Loss:      1.6549054631724902\n",
      "\n",
      "\n",
      "Epoch:70\n",
      "Validation Loss: 1.6479626893997192\n",
      "Train Loss:      1.654075053323924\n",
      "\n",
      "\n",
      "Epoch:71\n",
      "Validation Loss: 1.6475213766098022\n",
      "Train Loss:      1.6532726168220018\n",
      "\n",
      "\n",
      "Epoch:72\n",
      "Validation Loss: 1.6469969749450684\n",
      "Train Loss:      1.6525445599044484\n",
      "\n",
      "\n",
      "Epoch:73\n",
      "Validation Loss: 1.6459320783615112\n",
      "Train Loss:      1.6518497887779684\n",
      "\n",
      "\n",
      "Epoch:74\n",
      "Validation Loss: 1.645094871520996\n",
      "Train Loss:      1.650939459619225\n",
      "\n",
      "\n",
      "Epoch:75\n",
      "Validation Loss: 1.64436936378479\n",
      "Train Loss:      1.65022835187021\n",
      "\n",
      "\n",
      "Epoch:76\n",
      "Validation Loss: 1.643734335899353\n",
      "Train Loss:      1.6493373655530408\n",
      "\n",
      "\n",
      "Epoch:77\n",
      "Validation Loss: 1.643091082572937\n",
      "Train Loss:      1.6486069079501406\n",
      "\n",
      "\n",
      "Epoch:78\n",
      "Validation Loss: 1.6418592929840088\n",
      "Train Loss:      1.647570631908298\n",
      "\n",
      "\n",
      "Epoch:79\n",
      "Validation Loss: 1.6415170431137085\n",
      "Train Loss:      1.6465896293778732\n",
      "\n",
      "\n",
      "Epoch:80\n",
      "Validation Loss: 1.6409908533096313\n",
      "Train Loss:      1.645625823509322\n",
      "\n",
      "\n",
      "Epoch:81\n",
      "Validation Loss: 1.6404987573623657\n",
      "Train Loss:      1.644869323832766\n",
      "\n",
      "\n",
      "Epoch:82\n",
      "Validation Loss: 1.6402993202209473\n",
      "Train Loss:      1.6442754470765797\n",
      "\n",
      "\n",
      "Epoch:83\n",
      "Validation Loss: 1.6398437023162842\n",
      "Train Loss:      1.6437631185492017\n",
      "\n",
      "\n",
      "Epoch:84\n",
      "Validation Loss: 1.6394866704940796\n",
      "Train Loss:      1.6432566440641674\n",
      "\n",
      "\n",
      "Epoch:85\n",
      "Validation Loss: 1.6390653848648071\n",
      "Train Loss:      1.6428015190837293\n",
      "\n",
      "\n",
      "Epoch:86\n",
      "Validation Loss: 1.6388037204742432\n",
      "Train Loss:      1.6423405474857475\n",
      "\n",
      "\n",
      "Epoch:87\n",
      "Validation Loss: 1.6385115385055542\n",
      "Train Loss:      1.6419771917963524\n",
      "\n",
      "\n",
      "Epoch:88\n",
      "Validation Loss: 1.6379950046539307\n",
      "Train Loss:      1.6415812470096205\n",
      "\n",
      "\n",
      "Epoch:89\n",
      "Validation Loss: 1.637690544128418\n",
      "Train Loss:      1.6411358019059916\n",
      "\n",
      "\n",
      "Epoch:90\n",
      "Validation Loss: 1.6372454166412354\n",
      "Train Loss:      1.6407790386140553\n",
      "\n",
      "\n",
      "Epoch:91\n",
      "Validation Loss: 1.6367285251617432\n",
      "Train Loss:      1.6403342411179855\n",
      "\n",
      "\n",
      "Epoch:92\n",
      "Validation Loss: 1.636474370956421\n",
      "Train Loss:      1.6399637840198398\n",
      "\n",
      "\n",
      "Epoch:93\n",
      "Validation Loss: 1.6361223459243774\n",
      "Train Loss:      1.639489827271564\n",
      "\n",
      "\n",
      "Epoch:94\n",
      "Validation Loss: 1.6359145641326904\n",
      "Train Loss:      1.6390296121782084\n",
      "\n",
      "\n",
      "Epoch:95\n",
      "Validation Loss: 1.6354502439498901\n",
      "Train Loss:      1.6387030228611508\n",
      "\n",
      "\n",
      "Epoch:96\n",
      "Validation Loss: 1.6349331140518188\n",
      "Train Loss:      1.6383292361526753\n",
      "\n",
      "\n",
      "Epoch:97\n",
      "Validation Loss: 1.634804606437683\n",
      "Train Loss:      1.6379924963089834\n",
      "\n",
      "\n",
      "Epoch:98\n",
      "Validation Loss: 1.634435772895813\n",
      "Train Loss:      1.637603020585532\n",
      "\n",
      "\n",
      "Epoch:99\n",
      "Validation Loss: 1.6342390775680542\n",
      "Train Loss:      1.6372921767944284\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric_dict = {'losses_trn': [],'losses_val':[]} \n",
    "encoder =  Encoder(grapheme_shape=v,hidden_units=10,embedding_units=10)\n",
    "decoder = Decoder(embedding_units=10,layer_1_n=15,grapheme_shape=v,encoder=encoder)\n",
    "optimizer = optim.Adam(decoder.parameters(), amsgrad=False, weight_decay=0.0)\n",
    "\n",
    "trn_loss = nn.NLLLoss(weight=freqs.float())\n",
    "val_loss = nn.NLLLoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    print(\"Epoch:\" + str(epoch))\n",
    "    epoch_trn_loss_sum = 0\n",
    "    for batch in (range(batches)):\n",
    "        x_batch = x_trn[batch_size*batch:batch_size*(batch+1)]\n",
    "        y_batch = y_trn[batch_size*batch:batch_size*(batch+1)]\n",
    "        \n",
    "        out = decoder.forward(x_batch)\n",
    "        log_softmax = F.log_softmax(out, dim=1).unsqueeze(2)\n",
    "        \n",
    "       \n",
    "        \n",
    "        NLL_Loss = trn_loss(log_softmax,y_batch.long()) \n",
    "        optimizer.zero_grad()\n",
    "        NLL_Loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_trn_loss_sum += NLL_Loss.item()\n",
    "        \n",
    "    out_val = decoder.forward(x_val)\n",
    "    log_val_softmax = F.log_softmax(out_val, dim=1).unsqueeze(2)\n",
    "    NLL_val_loss = trn_loss(log_val_softmax, y_val.long())\n",
    "    \n",
    "    epoch_trn_loss = epoch_trn_loss_sum/batches\n",
    "    print(\"Validation Loss: \"+str(NLL_val_loss.item()))\n",
    "    print(\"Train Loss:      \"+str(epoch_trn_loss))\n",
    "    print(\"\\n\")\n",
    "   # print(\"Val: \"+str(val_loss.item()))\n",
    "    metric_dict['losses_trn'].append(NLL_Loss.item())\n",
    "    metric_dict['losses_val'].append(epoch_trn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd75778b790>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(metric_dict['losses_trn'][:100])\n",
    "plt.plot(metric_dict['losses_val'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = np.zeros(shape=(len(vocab),10))\n",
    "\n",
    "i=0\n",
    "for grapheme in vocab:\n",
    "    test = torch.from_numpy(graph2vec(grapheme)).float()\n",
    "    embedding = decoder.encode(test).detach().numpy()\n",
    "    embeddings[i,:]=embedding\n",
    "    i+=1\n",
    "\n",
    "\n",
    "\n",
    "embedding_means = embeddings.mean(axis=0)\n",
    "embedding_std = embeddings.std(axis=0)\n",
    "norm_embeddings = (embeddings-embedding_means)/embedding_std\n",
    "\n",
    "    \n",
    "covariance_matrix = np.cov(norm_embeddings.T)\n",
    "v,w = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "idx = v.argsort()[::-1] # Sort descending and get sorted indices\n",
    "v = v[idx] # Use indices on eigv vector\n",
    "w = w[:,idx] # \n",
    "\n",
    "variance_explained = []\n",
    "for i in v:\n",
    "     variance_explained.append((i/sum(v))*100)\n",
    "        \n",
    "red_Vecs = w[0:2,:]\n",
    "\n",
    "low_d_embed = (embeddings @ red_Vecs.T)\n",
    "\n",
    "#plt.scatter(x=low_d_embed[:,0],y=low_d_embed[:,1])\n",
    "\n",
    "x=low_d_embed[:,0]\n",
    "y=low_d_embed[:,1]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y,color='white')\n",
    "\n",
    "for i, txt in enumerate(vocab):\n",
    "    ax.annotate(txt, (x[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n', 'g']\n",
      "Prediction: ng e\n",
      "True:       ng £\n"
     ]
    }
   ],
   "source": [
    "n=randint(0,x_trn.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "input = x_trn[n,:,:].unsqueeze(0)\n",
    "output = y_trn[n,:]\n",
    "\n",
    "out=decoder.forward(input)\n",
    "log_softmax = -F.log_softmax(out, dim=1)\n",
    "\n",
    "p=(log_softmax.argmin(dim=1).detach().numpy()[0])\n",
    "o=(output.int().numpy())\n",
    "\n",
    "numpy_input = input.int().detach().numpy()[0]\n",
    "inp_ind = (numpy_input.argmax(axis=1))\n",
    "inp_let = [vocab[i] for i in inp_ind]\n",
    "\n",
    "\n",
    "print(inp_let)\n",
    "print(\"Prediction: \" + ''.join(inp_let)+\" \"+str(vocab[p]))\n",
    "print(\"True:       \" + ''.join(inp_let)+\" \"+str(vocab[o[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', '$', 'w', 'e', 'i', 'ß', 'l', 'i', 'c', 'h', 'e', 'm']\n",
      "['h', 'e']\n",
      "33\n",
      "['h', 'e']\n",
      "Prediction: $$weißliche n\n",
      "True:       $$weißliche m\n"
     ]
    }
   ],
   "source": [
    "n=randint(0,len(tokens))\n",
    "token=(tokens[n])[:-1]\n",
    "print(token)\n",
    "\n",
    "input = token[-3:-1]\n",
    "\n",
    "#input = x_trn[n,:,:].unsqueeze(0)\n",
    "output = token[-1:][0]\n",
    "\n",
    "input = torch.tensor([graph2vec(input[0]),graph2vec(input[1])]).unsqueeze(0).float()\n",
    "\n",
    "out=decoder.forward(input)\n",
    "log_softmax = -F.log_softmax(out, dim=1)\n",
    "\n",
    "p=(log_softmax.argmin(dim=1).detach().numpy()[0])\n",
    "o=(output)\n",
    "\n",
    "numpy_input = input.int().detach().numpy()[0]\n",
    "inp_ind = (numpy_input.argmax(axis=1))\n",
    "inp_let = [vocab[i] for i in inp_ind]\n",
    "print(inp_let)\n",
    "print(p)\n",
    "\n",
    "\n",
    "print(inp_let)\n",
    "print(\"Prediction: \" + ''.join(token[:-1])+\" \"+str(vocab[p]))\n",
    "print(\"True:       \" + ''.join(token[:-1])+\" \"+str(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yieres norneitien yenden ßultiendtlen henden eretete ren qaet initeren amind$erteten\n"
     ]
    }
   ],
   "source": [
    "n=randint(0,len(tokens))\n",
    "token=(tokens[n])[:-1]\n",
    "sentence = []\n",
    "\n",
    "for i in range(10):\n",
    "    string = \"$$\"\n",
    "\n",
    "    while True:\n",
    "\n",
    "        input=string[-2:]\n",
    "        input = torch.tensor([graph2vec(input[0]),graph2vec(input[1])]).unsqueeze(0).float()\n",
    "\n",
    "        out=decoder.forward(input)\n",
    "        probs = F.softmax(out, dim=1).detach().numpy()[0]\n",
    "\n",
    "        sample = np.random.multinomial(1, probs)\n",
    "        ids = np.argmax(sample)\n",
    "\n",
    "        #p=(log_softmax.argmin(dim=1).detach().numpy()[0])\n",
    "\n",
    "        grapheme = str(vocab[ids])\n",
    "\n",
    "        string+=grapheme\n",
    "        if grapheme ==\"£\":\n",
    "            break\n",
    "\n",
    "    #string = string.split('$')[2:][0]\n",
    "    #string = string.split('£')[:-1][0]\n",
    "    sentence.append(string[2:-1])\n",
    "\n",
    "print(' '.join(sentence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbour of a : c\n",
      "Nearest neighbour of b : p\n",
      "Nearest neighbour of c : f\n",
      "Nearest neighbour of d : z\n",
      "Nearest neighbour of e : s\n",
      "Nearest neighbour of f : x\n",
      "Nearest neighbour of g : q\n",
      "Nearest neighbour of h : r\n",
      "Nearest neighbour of i : k\n",
      "Nearest neighbour of j : w\n",
      "Nearest neighbour of k : i\n",
      "Nearest neighbour of l : d\n",
      "Nearest neighbour of m : x\n",
      "Nearest neighbour of n : r\n",
      "Nearest neighbour of o : a\n",
      "Nearest neighbour of p : b\n",
      "Nearest neighbour of q : s\n",
      "Nearest neighbour of r : n\n",
      "Nearest neighbour of s : t\n",
      "Nearest neighbour of t : s\n",
      "Nearest neighbour of u : b\n",
      "Nearest neighbour of v : $\n",
      "Nearest neighbour of w : $\n",
      "Nearest neighbour of x : f\n",
      "Nearest neighbour of y : t\n",
      "Nearest neighbour of z : £\n",
      "Nearest neighbour of $ : v\n",
      "Nearest neighbour of £ : z\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.zeros(shape=(len(vocab),10))\n",
    "\n",
    "i=0\n",
    "for grapheme in vocab:\n",
    "    test = torch.from_numpy(graph2vec(grapheme)).float()\n",
    "    embedding = decoder.encode(test).detach().numpy()\n",
    "    embeddings[i,:]=embedding\n",
    "    i+=1\n",
    "    \n",
    "l=0\n",
    "for e in (embeddings):\n",
    "    dists=(np.square(embeddings-e).sum(axis=1))\n",
    "    nearest_idx=(np.argsort(dists)[1])\n",
    "    print(\"Nearest neighbour of \"+vocab[l]+\" : \"+vocab[nearest_idx])\n",
    "    l+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
